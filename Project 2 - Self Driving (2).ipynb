{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Import Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Install SWIG https://sourceforge.net/projects/swig/files/swigwin/swigwin-4.0.2/swigwin-4.0.2.zip/download?use_mirror=ixpeering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pyglet==1.3.2\n",
      "  Downloading pyglet-1.3.2-py2.py3-none-any.whl (1.0 MB)\n",
      "     ---------------------------------------- 0.0/1.0 MB ? eta -:--:--\n",
      "     ---- ----------------------------------- 0.1/1.0 MB 3.6 MB/s eta 0:00:01\n",
      "     -------------- ------------------------- 0.4/1.0 MB 3.7 MB/s eta 0:00:01\n",
      "     ------------------------------ --------- 0.8/1.0 MB 4.9 MB/s eta 0:00:01\n",
      "     ---------------------------------------- 1.0/1.0 MB 5.4 MB/s eta 0:00:00\n",
      "Requirement already satisfied: gym[box2d] in c:\\users\\omarb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.26.2)\n",
      "Collecting future (from pyglet==1.3.2)\n",
      "  Downloading future-0.18.3.tar.gz (840 kB)\n",
      "     ---------------------------------------- 0.0/840.9 kB ? eta -:--:--\n",
      "     --------------------------------- --- 757.8/840.9 kB 24.1 MB/s eta 0:00:01\n",
      "     ------------------------------------  839.7/840.9 kB 10.6 MB/s eta 0:00:01\n",
      "     -------------------------------------- 840.9/840.9 kB 8.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: numpy>=1.18.0 in c:\\users\\omarb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym[box2d]) (1.26.2)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\omarb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym[box2d]) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\omarb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym[box2d]) (0.0.8)\n",
      "Requirement already satisfied: importlib-metadata>=4.8.0 in c:\\users\\omarb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym[box2d]) (6.8.0)\n",
      "Requirement already satisfied: box2d-py==2.3.5 in c:\\users\\omarb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym[box2d]) (2.3.5)\n",
      "Requirement already satisfied: pygame==2.1.0 in c:\\users\\omarb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym[box2d]) (2.1.0)\n",
      "Requirement already satisfied: swig==4.* in c:\\users\\omarb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from gym[box2d]) (4.1.1.post1)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\omarb\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from importlib-metadata>=4.8.0->gym[box2d]) (3.17.0)\n",
      "Building wheels for collected packages: future\n",
      "  Building wheel for future (setup.py): started\n",
      "  Building wheel for future (setup.py): finished with status 'done'\n",
      "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492054 sha256=4c326b728736118191a4d10ec4b5904aee34736e921c5d8882c3782f34c200cb\n",
      "  Stored in directory: c:\\users\\omarb\\appdata\\local\\pip\\cache\\wheels\\bf\\5d\\6a\\2e53874f7ec4e2bede522385439531fafec8fafe005b5c3d1b\n",
      "Successfully built future\n",
      "Installing collected packages: future, pyglet\n",
      "  Attempting uninstall: pyglet\n",
      "    Found existing installation: pyglet 2.0.10\n",
      "    Uninstalling pyglet-2.0.10:\n",
      "      Successfully uninstalled pyglet-2.0.10\n",
      "Successfully installed future-0.18.3 pyglet-1.3.2\n"
     ]
    }
   ],
   "source": [
    "!pip install gym[box2d] pyglet==1.3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\omarb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym \n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.vec_env import VecFrameStack\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Test Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# environment_name = \"CarRacing-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name,  render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omarb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "\n",
    "def test_environment(environment_name):\n",
    "    env = None\n",
    "    try:\n",
    "        env = gym.make(environment_name, render_mode='human')\n",
    "        env.reset()\n",
    "\n",
    "        for _ in range(1000):\n",
    "            env.render()\n",
    "            action = env.action_space.sample()\n",
    "            step_result = env.step(action)\n",
    "            \n",
    "            # Unpack the first four values\n",
    "            next_state, reward, done, info = step_result[:4]\n",
    "\n",
    "            if done:\n",
    "                env.reset()\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "    finally:\n",
    "        if env is not None:\n",
    "            env.close()\n",
    "\n",
    "# Replace 'YourEnvironmentNameHere' with the name of your Gym environment\n",
    "test_environment('CarRacing-v2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# episodes = 5\n",
    "# for episode in range(1, episodes+1):\n",
    "#     state = env.reset()\n",
    "#     done = False\n",
    "#     score = 0 \n",
    "    \n",
    "#     while not done:\n",
    "#         env.render()\n",
    "#         action = env.action_space.sample()\n",
    "#         n_state, reward, done, info = env.step(action)\n",
    "#         score+=reward\n",
    "#     print('Episode:{} Score:{}'.format(episode, score))\n",
    "# env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_name = \"CarRacing-v2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(environment_name,  render_mode='human')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.52610314,  0.69233567,  0.55662674], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[220,  68,  20],\n",
       "        [222, 141,  25],\n",
       "        [141, 232,   7],\n",
       "        ...,\n",
       "        [ 52,  20, 160],\n",
       "        [ 91, 251, 186],\n",
       "        [152,   4,  23]],\n",
       "\n",
       "       [[109, 137,  67],\n",
       "        [176, 249, 122],\n",
       "        [233, 222, 150],\n",
       "        ...,\n",
       "        [107,  67,  35],\n",
       "        [152, 157, 243],\n",
       "        [ 23, 169, 172]],\n",
       "\n",
       "       [[ 53,  94,  91],\n",
       "        [173, 172,  40],\n",
       "        [ 97, 107, 196],\n",
       "        ...,\n",
       "        [241, 129,  52],\n",
       "        [155,  56, 202],\n",
       "        [ 11, 241, 131]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[ 43,  12,  61],\n",
       "        [  8,  95,  93],\n",
       "        [115, 117,  76],\n",
       "        ...,\n",
       "        [179,  78, 103],\n",
       "        [  4, 247, 143],\n",
       "        [124, 178,  89]],\n",
       "\n",
       "       [[142,  20, 171],\n",
       "        [229, 210, 161],\n",
       "        [151,  35, 244],\n",
       "        ...,\n",
       "        [128, 193, 217],\n",
       "        [ 20, 199, 169],\n",
       "        [136, 149,  18]],\n",
       "\n",
       "       [[142,   3, 250],\n",
       "        [ 64,  36,  10],\n",
       "        [ 75, 232,  46],\n",
       "        ...,\n",
       "        [203, 233,  36],\n",
       "        [123, 199,  46],\n",
       "        [ 21, 221, 147]]], dtype=uint8)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = os.path.join('Training', 'Logs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omarb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = PPO(\"CnnPolicy\", env, verbose=1, tensorboard_log=log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to Training\\Logs\\PPO_2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omarb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1e+03    |\n",
      "|    ep_rew_mean     | -54.7    |\n",
      "| time/              |          |\n",
      "|    fps             | 21       |\n",
      "|    iterations      | 1        |\n",
      "|    time_elapsed    | 95       |\n",
      "|    total_timesteps | 2048     |\n",
      "---------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -54.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 17          |\n",
      "|    iterations           | 2           |\n",
      "|    time_elapsed         | 230         |\n",
      "|    total_timesteps      | 4096        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.005867646 |\n",
      "|    clip_fraction        | 0.0657      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.24       |\n",
      "|    explained_variance   | 0.00219     |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.339       |\n",
      "|    n_updates            | 10          |\n",
      "|    policy_gradient_loss | -0.00549    |\n",
      "|    std                  | 0.988       |\n",
      "|    value_loss           | 0.642       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -51.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 16          |\n",
      "|    iterations           | 3           |\n",
      "|    time_elapsed         | 366         |\n",
      "|    total_timesteps      | 6144        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.008561011 |\n",
      "|    clip_fraction        | 0.122       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.21       |\n",
      "|    explained_variance   | 0.0264      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.125       |\n",
      "|    n_updates            | 20          |\n",
      "|    policy_gradient_loss | -0.0114     |\n",
      "|    std                  | 0.978       |\n",
      "|    value_loss           | 0.462       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| rollout/                |              |\n",
      "|    ep_len_mean          | 1e+03        |\n",
      "|    ep_rew_mean          | -50          |\n",
      "| time/                   |              |\n",
      "|    fps                  | 16           |\n",
      "|    iterations           | 4            |\n",
      "|    time_elapsed         | 505          |\n",
      "|    total_timesteps      | 8192         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 0.0064727785 |\n",
      "|    clip_fraction        | 0.0881       |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -4.18        |\n",
      "|    explained_variance   | 0.0401       |\n",
      "|    learning_rate        | 0.0003       |\n",
      "|    loss                 | 0.28         |\n",
      "|    n_updates            | 30           |\n",
      "|    policy_gradient_loss | -0.0064      |\n",
      "|    std                  | 0.971        |\n",
      "|    value_loss           | 0.691        |\n",
      "------------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -49         |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 5           |\n",
      "|    time_elapsed         | 640         |\n",
      "|    total_timesteps      | 10240       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.011702873 |\n",
      "|    clip_fraction        | 0.134       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.13       |\n",
      "|    explained_variance   | 0.14        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.172       |\n",
      "|    n_updates            | 40          |\n",
      "|    policy_gradient_loss | -0.0118     |\n",
      "|    std                  | 0.951       |\n",
      "|    value_loss           | 0.54        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -46.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 6           |\n",
      "|    time_elapsed         | 789         |\n",
      "|    total_timesteps      | 12288       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.006851606 |\n",
      "|    clip_fraction        | 0.0659      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.207       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.158       |\n",
      "|    n_updates            | 50          |\n",
      "|    policy_gradient_loss | -0.00689    |\n",
      "|    std                  | 0.95        |\n",
      "|    value_loss           | 0.582       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -46.8       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 903         |\n",
      "|    total_timesteps      | 14336       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.009461043 |\n",
      "|    clip_fraction        | 0.0893      |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.1        |\n",
      "|    explained_variance   | 0.242       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.122       |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -0.0116     |\n",
      "|    std                  | 0.948       |\n",
      "|    value_loss           | 0.483       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -45.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 8           |\n",
      "|    time_elapsed         | 1039        |\n",
      "|    total_timesteps      | 16384       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014147824 |\n",
      "|    clip_fraction        | 0.121       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.08       |\n",
      "|    explained_variance   | 0.304       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0686      |\n",
      "|    n_updates            | 70          |\n",
      "|    policy_gradient_loss | -0.0153     |\n",
      "|    std                  | 0.936       |\n",
      "|    value_loss           | 0.294       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -44.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 9           |\n",
      "|    time_elapsed         | 1185        |\n",
      "|    total_timesteps      | 18432       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.015495409 |\n",
      "|    clip_fraction        | 0.159       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.05       |\n",
      "|    explained_variance   | 0.0972      |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0573      |\n",
      "|    n_updates            | 80          |\n",
      "|    policy_gradient_loss | -0.0205     |\n",
      "|    std                  | 0.929       |\n",
      "|    value_loss           | 0.274       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -42.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 10          |\n",
      "|    time_elapsed         | 1338        |\n",
      "|    total_timesteps      | 20480       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.014038464 |\n",
      "|    clip_fraction        | 0.148       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -4.01       |\n",
      "|    explained_variance   | 0.272       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0501      |\n",
      "|    n_updates            | 90          |\n",
      "|    policy_gradient_loss | -0.0175     |\n",
      "|    std                  | 0.917       |\n",
      "|    value_loss           | 0.388       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -43.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 11          |\n",
      "|    time_elapsed         | 1486        |\n",
      "|    total_timesteps      | 22528       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019709736 |\n",
      "|    clip_fraction        | 0.198       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.97       |\n",
      "|    explained_variance   | 0.405       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0528      |\n",
      "|    n_updates            | 100         |\n",
      "|    policy_gradient_loss | -0.0313     |\n",
      "|    std                  | 0.901       |\n",
      "|    value_loss           | 0.25        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -42.4       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 12          |\n",
      "|    time_elapsed         | 1630        |\n",
      "|    total_timesteps      | 24576       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.016768362 |\n",
      "|    clip_fraction        | 0.17        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.93       |\n",
      "|    explained_variance   | 0.559       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.0231      |\n",
      "|    n_updates            | 110         |\n",
      "|    policy_gradient_loss | -0.0195     |\n",
      "|    std                  | 0.89        |\n",
      "|    value_loss           | 0.231       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -44.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 13          |\n",
      "|    time_elapsed         | 1768        |\n",
      "|    total_timesteps      | 26624       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.030821357 |\n",
      "|    clip_fraction        | 0.184       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.89       |\n",
      "|    explained_variance   | 0.787       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.021       |\n",
      "|    n_updates            | 120         |\n",
      "|    policy_gradient_loss | -0.0246     |\n",
      "|    std                  | 0.879       |\n",
      "|    value_loss           | 0.198       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -44.6       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 14          |\n",
      "|    time_elapsed         | 1921        |\n",
      "|    total_timesteps      | 28672       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.023468688 |\n",
      "|    clip_fraction        | 0.218       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.86       |\n",
      "|    explained_variance   | 0.837       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00017     |\n",
      "|    n_updates            | 130         |\n",
      "|    policy_gradient_loss | -0.0237     |\n",
      "|    std                  | 0.875       |\n",
      "|    value_loss           | 0.0909      |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -43.9       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 15          |\n",
      "|    time_elapsed         | 2065        |\n",
      "|    total_timesteps      | 30720       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.019667458 |\n",
      "|    clip_fraction        | 0.211       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.85       |\n",
      "|    explained_variance   | 0.88        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00755     |\n",
      "|    n_updates            | 140         |\n",
      "|    policy_gradient_loss | -0.0231     |\n",
      "|    std                  | 0.869       |\n",
      "|    value_loss           | 0.202       |\n",
      "-----------------------------------------\n",
      "--------------------------------------\n",
      "| rollout/                |          |\n",
      "|    ep_len_mean          | 1e+03    |\n",
      "|    ep_rew_mean          | -41.3    |\n",
      "| time/                   |          |\n",
      "|    fps                  | 14       |\n",
      "|    iterations           | 16       |\n",
      "|    time_elapsed         | 2202     |\n",
      "|    total_timesteps      | 32768    |\n",
      "| train/                  |          |\n",
      "|    approx_kl            | 0.023678 |\n",
      "|    clip_fraction        | 0.235    |\n",
      "|    clip_range           | 0.2      |\n",
      "|    entropy_loss         | -3.82    |\n",
      "|    explained_variance   | 0.781    |\n",
      "|    learning_rate        | 0.0003   |\n",
      "|    loss                 | 0.0422   |\n",
      "|    n_updates            | 150      |\n",
      "|    policy_gradient_loss | -0.0282  |\n",
      "|    std                  | 0.86     |\n",
      "|    value_loss           | 0.323    |\n",
      "--------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -38.7       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 14          |\n",
      "|    iterations           | 17          |\n",
      "|    time_elapsed         | 2326        |\n",
      "|    total_timesteps      | 34816       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.022137966 |\n",
      "|    clip_fraction        | 0.21        |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.79       |\n",
      "|    explained_variance   | 0.81        |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.161       |\n",
      "|    n_updates            | 160         |\n",
      "|    policy_gradient_loss | -0.0268     |\n",
      "|    std                  | 0.851       |\n",
      "|    value_loss           | 0.575       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -35.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 18          |\n",
      "|    time_elapsed         | 2456        |\n",
      "|    total_timesteps      | 36864       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.027361544 |\n",
      "|    clip_fraction        | 0.213       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.75       |\n",
      "|    explained_variance   | 0.864       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | -0.0133     |\n",
      "|    n_updates            | 170         |\n",
      "|    policy_gradient_loss | -0.0308     |\n",
      "|    std                  | 0.84        |\n",
      "|    value_loss           | 0.37        |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -33.1       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 19          |\n",
      "|    time_elapsed         | 2577        |\n",
      "|    total_timesteps      | 38912       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.020578861 |\n",
      "|    clip_fraction        | 0.225       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.71       |\n",
      "|    explained_variance   | 0.847       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.138       |\n",
      "|    n_updates            | 180         |\n",
      "|    policy_gradient_loss | -0.0287     |\n",
      "|    std                  | 0.827       |\n",
      "|    value_loss           | 0.443       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| rollout/                |             |\n",
      "|    ep_len_mean          | 1e+03       |\n",
      "|    ep_rew_mean          | -32.3       |\n",
      "| time/                   |             |\n",
      "|    fps                  | 15          |\n",
      "|    iterations           | 20          |\n",
      "|    time_elapsed         | 2697        |\n",
      "|    total_timesteps      | 40960       |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 0.025193807 |\n",
      "|    clip_fraction        | 0.236       |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -3.67       |\n",
      "|    explained_variance   | 0.937       |\n",
      "|    learning_rate        | 0.0003      |\n",
      "|    loss                 | 0.00241     |\n",
      "|    n_updates            | 190         |\n",
      "|    policy_gradient_loss | -0.0295     |\n",
      "|    std                  | 0.816       |\n",
      "|    value_loss           | 0.341       |\n",
      "-----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x21fc8985580>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=40000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Save Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppo_path = os.path.join('Training', 'Saved Models', 'PPO_Driving_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(ppo_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Evaluate and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\omarb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n",
      "c:\\Users\\omarb\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\stable_baselines3\\common\\evaluation.py:67: UserWarning: Evaluation environment is not wrapped with a ``Monitor`` wrapper. This may result in reporting modified episode lengths and rewards, if other wrappers happen to modify these. Consider wrapping environment first with ``Monitor`` wrapper.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(228.14651382640005, 185.22464674466866)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate_policy(model, env, n_eval_episodes=10, render=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 0)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pygame\n",
    "pygame.init()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'env' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m obs \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[0;32m      3\u001b[0m     action, _states \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(obs)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'env' is not defined"
     ]
    }
   ],
   "source": [
    "obs = env.reset()\n",
    "while True:\n",
    "    action, _states = model.predict(obs)\n",
    "    obs, rewards, dones, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
